{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262ffc9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7644/3547685711.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prepare\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Prepare\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e506afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ada44d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92c95152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "399a246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9182a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prefiction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f45c8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e67dc7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------------------------\n",
      "loss: 1.146548 [    0/60000]\n",
      "loss: 1.151985 [ 6400/60000]\n",
      "loss: 0.968065 [12800/60000]\n",
      "loss: 1.106459 [19200/60000]\n",
      "loss: 0.976020 [25600/60000]\n",
      "loss: 1.015073 [32000/60000]\n",
      "loss: 1.044953 [38400/60000]\n",
      "loss: 0.990041 [44800/60000]\n",
      "loss: 1.019869 [51200/60000]\n",
      "loss: 0.965535 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.974077 \n",
      "\n",
      "Epoch 2\n",
      "-----------------------------------------\n",
      "loss: 1.027084 [    0/60000]\n",
      "loss: 1.055634 [ 6400/60000]\n",
      "loss: 0.854936 [12800/60000]\n",
      "loss: 1.015586 [19200/60000]\n",
      "loss: 0.890889 [25600/60000]\n",
      "loss: 0.921619 [32000/60000]\n",
      "loss: 0.969441 [38400/60000]\n",
      "loss: 0.917058 [44800/60000]\n",
      "loss: 0.940622 [51200/60000]\n",
      "loss: 0.899942 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.902751 \n",
      "\n",
      "Epoch 3\n",
      "-----------------------------------------\n",
      "loss: 0.939808 [    0/60000]\n",
      "loss: 0.988819 [ 6400/60000]\n",
      "loss: 0.773952 [12800/60000]\n",
      "loss: 0.951930 [19200/60000]\n",
      "loss: 0.834611 [25600/60000]\n",
      "loss: 0.853811 [32000/60000]\n",
      "loss: 0.916395 [38400/60000]\n",
      "loss: 0.868769 [44800/60000]\n",
      "loss: 0.884343 [51200/60000]\n",
      "loss: 0.853147 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.851842 \n",
      "\n",
      "Epoch 4\n",
      "-----------------------------------------\n",
      "loss: 0.873476 [    0/60000]\n",
      "loss: 0.939020 [ 6400/60000]\n",
      "loss: 0.713876 [12800/60000]\n",
      "loss: 0.905002 [19200/60000]\n",
      "loss: 0.794591 [25600/60000]\n",
      "loss: 0.803215 [32000/60000]\n",
      "loss: 0.876010 [38400/60000]\n",
      "loss: 0.835292 [44800/60000]\n",
      "loss: 0.842655 [51200/60000]\n",
      "loss: 0.817319 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.813475 \n",
      "\n",
      "Epoch 5\n",
      "-----------------------------------------\n",
      "loss: 0.820889 [    0/60000]\n",
      "loss: 0.899402 [ 6400/60000]\n",
      "loss: 0.667468 [12800/60000]\n",
      "loss: 0.868754 [19200/60000]\n",
      "loss: 0.764343 [25600/60000]\n",
      "loss: 0.764713 [32000/60000]\n",
      "loss: 0.843238 [38400/60000]\n",
      "loss: 0.810736 [44800/60000]\n",
      "loss: 0.810712 [51200/60000]\n",
      "loss: 0.788403 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.783126 \n",
      "\n",
      "Epoch 6\n",
      "-----------------------------------------\n",
      "loss: 0.778044 [    0/60000]\n",
      "loss: 0.866055 [ 6400/60000]\n",
      "loss: 0.630390 [12800/60000]\n",
      "loss: 0.839867 [19200/60000]\n",
      "loss: 0.740241 [25600/60000]\n",
      "loss: 0.734684 [32000/60000]\n",
      "loss: 0.815035 [38400/60000]\n",
      "loss: 0.791185 [44800/60000]\n",
      "loss: 0.784964 [51200/60000]\n",
      "loss: 0.764078 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.757944 \n",
      "\n",
      "Epoch 7\n",
      "-----------------------------------------\n",
      "loss: 0.741736 [    0/60000]\n",
      "loss: 0.836661 [ 6400/60000]\n",
      "loss: 0.599526 [12800/60000]\n",
      "loss: 0.815942 [19200/60000]\n",
      "loss: 0.720045 [25600/60000]\n",
      "loss: 0.710533 [32000/60000]\n",
      "loss: 0.790058 [38400/60000]\n",
      "loss: 0.774734 [44800/60000]\n",
      "loss: 0.763563 [51200/60000]\n",
      "loss: 0.742922 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.736209 \n",
      "\n",
      "Epoch 8\n",
      "-----------------------------------------\n",
      "loss: 0.710247 [    0/60000]\n",
      "loss: 0.810184 [ 6400/60000]\n",
      "loss: 0.573227 [12800/60000]\n",
      "loss: 0.795602 [19200/60000]\n",
      "loss: 0.702456 [25600/60000]\n",
      "loss: 0.690593 [32000/60000]\n",
      "loss: 0.767257 [38400/60000]\n",
      "loss: 0.760045 [44800/60000]\n",
      "loss: 0.745213 [51200/60000]\n",
      "loss: 0.724136 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.716918 \n",
      "\n",
      "Epoch 9\n",
      "-----------------------------------------\n",
      "loss: 0.682395 [    0/60000]\n",
      "loss: 0.785972 [ 6400/60000]\n",
      "loss: 0.550216 [12800/60000]\n",
      "loss: 0.777785 [19200/60000]\n",
      "loss: 0.687104 [25600/60000]\n",
      "loss: 0.673667 [32000/60000]\n",
      "loss: 0.746137 [38400/60000]\n",
      "loss: 0.746510 [44800/60000]\n",
      "loss: 0.729055 [51200/60000]\n",
      "loss: 0.707153 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.699485 \n",
      "\n",
      "Epoch 10\n",
      "-----------------------------------------\n",
      "loss: 0.657483 [    0/60000]\n",
      "loss: 0.763705 [ 6400/60000]\n",
      "loss: 0.529792 [12800/60000]\n",
      "loss: 0.761702 [19200/60000]\n",
      "loss: 0.673275 [25600/60000]\n",
      "loss: 0.659135 [32000/60000]\n",
      "loss: 0.726512 [38400/60000]\n",
      "loss: 0.734105 [44800/60000]\n",
      "loss: 0.714778 [51200/60000]\n",
      "loss: 0.691523 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.683523 \n",
      "\n",
      "Epoch 11\n",
      "-----------------------------------------\n",
      "loss: 0.634943 [    0/60000]\n",
      "loss: 0.743117 [ 6400/60000]\n",
      "loss: 0.511578 [12800/60000]\n",
      "loss: 0.747113 [19200/60000]\n",
      "loss: 0.660776 [25600/60000]\n",
      "loss: 0.646408 [32000/60000]\n",
      "loss: 0.708056 [38400/60000]\n",
      "loss: 0.722666 [44800/60000]\n",
      "loss: 0.702069 [51200/60000]\n",
      "loss: 0.677041 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.668819 \n",
      "\n",
      "Epoch 12\n",
      "-----------------------------------------\n",
      "loss: 0.614607 [    0/60000]\n",
      "loss: 0.724031 [ 6400/60000]\n",
      "loss: 0.495226 [12800/60000]\n",
      "loss: 0.733613 [19200/60000]\n",
      "loss: 0.649758 [25600/60000]\n",
      "loss: 0.635257 [32000/60000]\n",
      "loss: 0.690904 [38400/60000]\n",
      "loss: 0.712228 [44800/60000]\n",
      "loss: 0.690556 [51200/60000]\n",
      "loss: 0.663722 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.655253 \n",
      "\n",
      "Epoch 13\n",
      "-----------------------------------------\n",
      "loss: 0.596215 [    0/60000]\n",
      "loss: 0.706376 [ 6400/60000]\n",
      "loss: 0.480394 [12800/60000]\n",
      "loss: 0.721141 [19200/60000]\n",
      "loss: 0.639810 [25600/60000]\n",
      "loss: 0.625418 [32000/60000]\n",
      "loss: 0.674937 [38400/60000]\n",
      "loss: 0.702821 [44800/60000]\n",
      "loss: 0.680376 [51200/60000]\n",
      "loss: 0.651308 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.642736 \n",
      "\n",
      "Epoch 14\n",
      "-----------------------------------------\n",
      "loss: 0.579553 [    0/60000]\n",
      "loss: 0.690161 [ 6400/60000]\n",
      "loss: 0.466790 [12800/60000]\n",
      "loss: 0.709519 [19200/60000]\n",
      "loss: 0.630721 [25600/60000]\n",
      "loss: 0.616624 [32000/60000]\n",
      "loss: 0.660150 [38400/60000]\n",
      "loss: 0.694566 [44800/60000]\n",
      "loss: 0.671338 [51200/60000]\n",
      "loss: 0.639643 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.631168 \n",
      "\n",
      "Epoch 15\n",
      "-----------------------------------------\n",
      "loss: 0.564358 [    0/60000]\n",
      "loss: 0.675173 [ 6400/60000]\n",
      "loss: 0.454362 [12800/60000]\n",
      "loss: 0.698682 [19200/60000]\n",
      "loss: 0.622294 [25600/60000]\n",
      "loss: 0.608661 [32000/60000]\n",
      "loss: 0.646346 [38400/60000]\n",
      "loss: 0.687216 [44800/60000]\n",
      "loss: 0.663517 [51200/60000]\n",
      "loss: 0.628585 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.620467 \n",
      "\n",
      "Epoch 16\n",
      "-----------------------------------------\n",
      "loss: 0.550425 [    0/60000]\n",
      "loss: 0.661459 [ 6400/60000]\n",
      "loss: 0.442874 [12800/60000]\n",
      "loss: 0.688452 [19200/60000]\n",
      "loss: 0.614690 [25600/60000]\n",
      "loss: 0.601474 [32000/60000]\n",
      "loss: 0.633689 [38400/60000]\n",
      "loss: 0.680903 [44800/60000]\n",
      "loss: 0.656704 [51200/60000]\n",
      "loss: 0.617983 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.610540 \n",
      "\n",
      "Epoch 17\n",
      "-----------------------------------------\n",
      "loss: 0.537644 [    0/60000]\n",
      "loss: 0.648825 [ 6400/60000]\n",
      "loss: 0.432357 [12800/60000]\n",
      "loss: 0.678995 [19200/60000]\n",
      "loss: 0.607790 [25600/60000]\n",
      "loss: 0.595043 [32000/60000]\n",
      "loss: 0.621925 [38400/60000]\n",
      "loss: 0.675756 [44800/60000]\n",
      "loss: 0.651100 [51200/60000]\n",
      "loss: 0.607984 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.601403 \n",
      "\n",
      "Epoch 18\n",
      "-----------------------------------------\n",
      "loss: 0.525807 [    0/60000]\n",
      "loss: 0.637223 [ 6400/60000]\n",
      "loss: 0.422625 [12800/60000]\n",
      "loss: 0.670145 [19200/60000]\n",
      "loss: 0.601067 [25600/60000]\n",
      "loss: 0.589032 [32000/60000]\n",
      "loss: 0.611027 [38400/60000]\n",
      "loss: 0.671619 [44800/60000]\n",
      "loss: 0.646040 [51200/60000]\n",
      "loss: 0.598446 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.592965 \n",
      "\n",
      "Epoch 19\n",
      "-----------------------------------------\n",
      "loss: 0.514845 [    0/60000]\n",
      "loss: 0.626450 [ 6400/60000]\n",
      "loss: 0.413645 [12800/60000]\n",
      "loss: 0.661939 [19200/60000]\n",
      "loss: 0.594590 [25600/60000]\n",
      "loss: 0.583335 [32000/60000]\n",
      "loss: 0.600962 [38400/60000]\n",
      "loss: 0.668367 [44800/60000]\n",
      "loss: 0.641896 [51200/60000]\n",
      "loss: 0.589377 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.585143 \n",
      "\n",
      "Epoch 20\n",
      "-----------------------------------------\n",
      "loss: 0.504669 [    0/60000]\n",
      "loss: 0.616634 [ 6400/60000]\n",
      "loss: 0.405196 [12800/60000]\n",
      "loss: 0.654118 [19200/60000]\n",
      "loss: 0.588349 [25600/60000]\n",
      "loss: 0.578017 [32000/60000]\n",
      "loss: 0.591609 [38400/60000]\n",
      "loss: 0.665825 [44800/60000]\n",
      "loss: 0.638257 [51200/60000]\n",
      "loss: 0.580727 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.577882 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-----------------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81d512af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "# Saving model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "545a3558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading models\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f25b9e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da88e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
